version: '3.8'

services:
  # Development service
  ai-interview-dev:
    build:
      context: .
      target: builder
    ports:
      - "3000:3000"
    volumes:
      - .:/app
      - /app/node_modules
      - /app/.next
    environment:
      - NODE_ENV=development
      - NEXT_TELEMETRY_DISABLED=1
    command: npm run dev
    profiles:
      - dev

  # Production service
  ai-interview-prod:
    build:
      context: .
      target: runner
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
    restart: unless-stopped
    profiles:
      - prod

  # Production service with reverse proxy
  ai-interview-prod-nginx:
    build:
      context: .
      target: runner
    environment:
      - NODE_ENV=production
      - NEXT_TELEMETRY_DISABLED=1
    restart: unless-stopped
    profiles:
      - prod-nginx

  # Nginx reverse proxy for production
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - ai-interview-prod-nginx
    restart: unless-stopped
    profiles:
      - prod-nginx

  # Redis for caching and rate limiting
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    profiles:
      - prod
      - prod-nginx

  # PostgreSQL for data persistence (optional)
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: ai_interview
      POSTGRES_USER: ai_user
      POSTGRES_PASSWORD: ai_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped
    profiles:
      - prod
      - prod-nginx

volumes:
  redis_data:
  postgres_data:

networks:
  default:
    name: ai-interview-network
